#
# 20200623 jens heine 
#          dennis brossat
#          benjamin heine
#
# dupfinder - identify duplicate files
#
#set -x

FILELIST_DB="filelist.db"
FILEHASH_DB="filehash.db"
FILES_WITH_HASH_DB="fileswithash.db"
FILEHASH_DB_TMP="filehash.db.tmp"
DUPLICATES_DB="duplicates.db"
DUPLICATE_FILES_ARCHIVE_FOLDER="duplicates"
COPY_DUPLICATES_SCRIPT="copy_dups_from_root_path_to_archive.sh"
DELETE_DUPLICATES_FROM_ROOT_SCRIPT="delete_dups_from_root_path.sh"
ROOT_PATH=""
HASH_CMD="md5sum"
DEBUG=0
VERSION="20200724"
RECALC_EXISTING_HASHES="0"
USAGE_INFO_TEXT="

NAME
	dupfinder

DESCRIPTION

Use dupfinder to find duplicate files in big archives of files.
Dupfinder searches the given path for files, creates a hash database for
all files and searches for files which have the same hash. So if you
have a picture or video with 2 diffenrent names or in different folders,
you can identify them and create an archive script and a delete script.

Dupfinder can be used to search for duplicate pictures in huge picture
collections for example.

SYNOPSIS

	dupfinder OPTIONS
   
OPTIONS

	-a Search in path for duplicates (requires -r to set the root path). 
	   This option scans the root path for files, creates hashes for them 
	   and searches for duplicate files. You can use dupfinder -g 
	   later to generate scripts for moving the duplicates to an archive 
	   folder. So if you have a picture or video with 2 diffenrent names or 
	   in different folders, you can identify them and create an archive 
	   script and a delete script.
	   The delete script will only delete duplicates - one version of the
	   duplicate files will be kept in the root path.
	-c Calculate hashes for files in filelist file and add them to 
	   filehash database
	-C Create duplicate files file from hash database
	-d Show contents of duplicates file
	-f search root path for files and create plain files file (requires -r)
	-g Generate scripts to copy duplicates and to delete duplicates
	-h Show usage information
	-H Show contents of hash database
	-n Calculate new hash for all files found, even if they exist in hash db
	-p Create filelist database for root path (requires -r)
	-P Show contents of filelist database
	-r [PATH] set root path
	-R Delete filehash database files
	-s Show statistics of database
	-v Verbose mode
	-V Show program version

EXAMPLES

1) To search duplicate files in path /tmp/picture use:

	> ./dupfinder -avr /tmp/Pictures

   3 files will be created:

	> filelist.db - list of files in root path
	> filehash.db - list of all files with every hash value
	> duplicates.db - list of duplicate files in
			
2) To get help for all options use:

	> ./dupfinder -h
	
3) To generate 2 scripts which can be used to archive the duplicates to
   an archive folder and to delete the duplicates use:
   
	> ./dupfinder -g
	
   2 scripts will be generated:
   
	> copy_dups_from_root_path_to_archive.sh 
   
   This script which will copy all duplicates in root path to
   an archive folder in your current directory called \"duplicates\".
   
   	> delete_dups_from_root_path.sh
	
   This script can be used to delete all duplicate files from the
   root path. If you want to exclude several folders, you can modify
   the script with grep for example.
   The delete script contents only the duplicates. If there are 3
   similar files, the delete script will only have 2 of them deleted.
   
   Just have a look into the delete script:
   
   > tail delete_dups_from_root_path.sh 
     rm -v '/tmp/2015/921.JPG'
     rm -v '/tmp/2015/.thumbs/923.JPG'
     
   If you don't want to delete file from the thumbnail folders, create
   a new script:
   
   > grep -v \".thumbs\" > delete_dups_from_root_path_custom.sh

4) To find out about the duplicates statistics use:

   > ./dupfinder -s

     Dupfinder Statistics

     Files in filehash database : 4774	(537 Kb)	modified: 2020-10-03 17:06:59.953627326 +0200
     Files in plain file list   : 4774	(378 Kb)	modified: 2020-10-03 17:06:08.454297780 +0200
     Files in duplicates file   : 1529	(130 Kb)	modified: 2020-10-03 17:07:04.149572704 +0200
     Size of all duplicates     : 1.489 GB     

REPORTING BUGS
	Report bugs to <binbash@gmx.net>

AUTHOR
	dupfinder by Jens Heine <binbash@gmx.net> 2020
	             and Dennis Brossat <dennis.brossat@email.de>
		     and Benjamin Heine <benjaminheine@gmx.net>

"


#
# Functions
#

function cleanUpAndExit() {
	echo
	logInfo "STRG-C detected. Cleaning up..."
#	showStats
	logInfo "Exiting."
	exit 0
}

trap cleanUpAndExit SIGINT

function logInfo() {
	if [ $DEBUG -eq 1 ]; then
		echo "> $1"
	fi
}

# Count and print lines in given file
function countEntriesInFile() {
	[ ! "$1" ] && {
		echo 0
	        return
	}
	if [ ! -r "${1}" ];then
		echo 0
		return
	fi
	FILE_COUNT=`wc -l ${1}|cut -d " " -f1`
	echo $FILE_COUNT
}

function countFileSizeInBytes() {
	[ ! "$1" ] && {
                echo 0
                return
        }
        if [ ! -r "${1}" ];then
                echo 0
                return
        fi
	FILE_SIZE=`wc -c ${1}|cut -d " " -f1`
	let FILE_SIZE="${FILE_SIZE}"/1024
	echo "$FILE_SIZE Kb"
}

function createPlainFileList() {
	[ "" == "$1" ] && return
	[ "" == "${FILELIST_DB}" ] && return
	logInfo "Creating full plain file list for root folder \"${ROOT_PATH}\""
	find ${ROOT_PATH} -type f 2>/dev/null | sort > ${FILELIST_DB}
	FILES_IN_FILELIST_DB=`countEntriesInFile ${FILELIST_DB}`
	logInfo "Fileslist DB has ${FILES_IN_FILELIST_DB} files."
	if [ ${RECALC_EXISTING_HASHES} -eq 0 ];then
		logInfo "Removing files that already have a hash value in the filehash database."
		if [ ! -s ${FILEHASH_DB} ];then
			logInfo "Filehash database does not exist or is empty."
			logInfo "Skipping to find already existing hashes for file in root path."
		else
			logInfo "Create file with filenames of existing files with hashes..."
			cat ${FILEHASH_DB} | cut -d ' ' -f2- | sed 's/^ //g' | sort > ${FILES_WITH_HASH_DB}
#			logInfo "Creating file with files in path: ${ROOT_PATH}..."
#			find ${ROOT_PATH} -type f 2>/dev/null | sort > ${FILELIST_DB}.tmp
			cp ${FILELIST_DB} ${FILELIST_DB}.tmp
			logInfo "Creating file with files in root path which have no hash..."
			diff --new-line-format="%L" --old-line-format="" --unchanged-line-format="" ${FILES_WITH_HASH_DB} ${FILELIST_DB}.tmp > ${FILELIST_DB}
		fi
		FILES_IN_FILELIST_DB=`countEntriesInFile ${FILELIST_DB}.tmp`
		logInfo "Files found in root path: ${FILES_IN_FILELIST_DB}"
		FILES_IN_FILELIST_DB_AFTER_DIFF=`countEntriesInFile ${FILELIST_DB}`
		SKIPPED_FILES_COUNT=$((${FILES_IN_FILELIST_DB} - ${FILES_IN_FILELIST_DB_AFTER_DIFF}))
		if [ ${FILES_IN_FILELIST_DB} -eq 0 ];then
			PERCENT_SKIPPED=0
		elif [ ${FILES_IN_FILELIST_DB_AFTER_DIFF} -eq 0 ];then
			PERCENT_SKIPPED=100
		else	
#			PERCENT_SKIPPED=`echo "100 * ( ${FILES_IN_FILELIST_DB} - ${FILES_IN_FILELIST_DB_AFTER_DIFF} ) / ${FILES_IN_FILELIST_DB}" | bc`
			PERCENT_SKIPPED=`awk -v f="$FILES_IN_FILELIST_DB" -v f2="$FILES_IN_FILELIST_DB_AFTER_DIFF" 'BEGIN { printf "%-.2f\n", 100*(f-f2)/f }'`
		fi
		logInfo "Files skipped because hashes are already in db: ${SKIPPED_FILES_COUNT} / ${PERCENT_SKIPPED}%"
		[ -f "${FILELIST_DB}.tmp" ] && rm "${FILELIST_DB}.tmp"
		[ -f "${FILES_WITH_HASH_DB}" ] && rm "${FILES_WITH_HASH_DB}"
	else
		logInfo "Calculate hashes for all files in root path, even if they exist in filehash database."
	fi
	logInfo "Filelist db: ${FILELIST_DB}"
	logInfo "Found `countEntriesInFile "${FILELIST_DB}"` file(s) to hash."
	logInfo "Plain file list filesize: `countFileSizeInBytes "${FILELIST_DB}" bytes`"
}

function createHash() {
	FILENAME="$1"
	[ "" == "$FILENAME" ] && return
	[ ! -r "$FILENAME" ] && return
	HASH=`$HASH_CMD "${FILENAME}"`
	echo "$HASH"
}

function deleteFilehashDatabase() {
        [ -f "${FILEHASH_DB}" ] && {
                logInfo "Deleting ${FILEHASH_DB}"
                rm "${FILEHASH_DB}"
		logInfo "Done."
        }
}

function deleteFilelistDatabase() {
        [ -f "${FILELIST_DB}" ] && {
                logInfo "Deleting ${FILELIST_DB}"
                rm "${FILELIST_DB}"
		logInfo "Done."
        }
}

function deleteDuplicatesDatabase() {
        [ -f "${DUPLICATES_DB}" ] && {
                logInfo "Deleting ${DUPLICATES_DB}"
                rm "${DUPLICATES_DB}"
		logInfo "Done."
        }
}

function deleteAllDatabases() {
	logInfo "Deleting all database files."
	deleteFilehashDatabase
	deleteFilelistDatabase
	deleteDuplicatesDatabase
}

function calculateHashesForPlainfilesFileIntoFileHashDatabase() {
	FILES_TO_HASH=`countEntriesInFile "${FILELIST_DB}"`
	[ "${FILES_TO_HASH}" -eq 0 ] && {
		logInfo "0 files in filelist database. No files to calculate hashes for."
		return
	}
	START_SECONDS=`date +%s`
	FILES_DONE=0
	NOW_SECONDS=`date +%s`
	ELAPSED_SECONDS=1
	HASH_RATE_PER_SECOND=1
	SHOW_STATS=0
	SECONDS_LEFT=1
	echo -n "Files done: "
	tput sc 2>/dev/null
	while read LINE;do
		CURRENTFILENAME="${LINE}"
		CURRENTHASH=`createHash "${CURRENTFILENAME}"`
		FILES_DONE=$((FILES_DONE+1))
		echo "${CURRENTHASH}" >> "${FILEHASH_DB}"
		NOW_SECONDS=`date +%s`
#		ELAPSED_SECONDS=`echo "$NOW_SECONDS - $START_SECONDS" | bc`
#		ELAPSED_SECONDS=`awk -v n="$NOW_SECONDS" -v n2="$START_SECONDS" 'BEGIN { printf "%d\n", n-n2 }'`
		ELAPSED_SECONDS=`echo $(($NOW_SECONDS - $START_SECONDS))`
		SHOW_STATS=$((${FILES_DONE} % 50))
		if [ ${SHOW_STATS} -eq 0 ];then
			[ $ELAPSED_SECONDS -eq 0 ] && ELAPSED_SECONDS=1
			HASH_RATE_PER_SECOND=$((${FILES_DONE} / ${ELAPSED_SECONDS}))
			FILES_LEFT=$((${FILES_TO_HASH} - ${FILES_DONE}))
			SECONDS_LEFT=$((${FILES_LEFT} / ${HASH_RATE_PER_SECOND}))
		fi
		echo -n "${FILES_DONE}/${FILES_TO_HASH} $HASH_RATE_PER_SECOND hashes/s ${SECONDS_LEFT}s left                 "
		tput rc 2>/dev/null
	done < ${FILELIST_DB}
	echo
	END_SECONDS=`date +%s`
#	SECONDS_NEEDED=`echo $END_SECONDS - $START_SECONDS | bc`
	SECONDS_NEEDED=`echo $(($END_SECONDS - $START_SECONDS))`
	if [ ${SECONDS_NEEDED} -ne 0 ];then
#		HASHES_PER_SECOND=`echo $FILES_TO_HASH / $SECONDS_NEEDED | bc`
		HASHES_PER_SECOND=`echo $(($FILES_TO_HASH / $SECONDS_NEEDED))`
	else
		HASHES_PER_SECOND=$FILES_TO_HASH
	fi
	echo "Time elapsed  : $SECONDS_NEEDED seconds"
	echo "Hashes/second : $HASHES_PER_SECOND"
	sortFileHashDatabase
	removeDuplicateFileHashDatabaseEntries
	logInfo "Done."
}

function sortFileHashDatabase() {
	logInfo "Sorting `countEntriesInFile "${FILEHASH_DB}"` files in filehash database..."
	cat "${FILEHASH_DB}" | sort > "${FILEHASH_DB_TMP}"
	logInfo "Moving ${FILEHASH_DB_TMP} to ${FILEHASH_DB}"
	mv "${FILEHASH_DB_TMP}" "${FILEHASH_DB}"
	logInfo "Sorting FileHashDatabase done."
}

function createDuplicateFilelist() {
	echo "Searching for duplicates in database..."
	FILES_IN_FILEHASH_DB=`countEntriesInFile "${FILEHASH_DB}"`
	[ "${FILES_IN_FILEHASH_DB}" -eq 0 ] && {
		logInfo "Filehash db is empty. No duplicates found."
		return
	}
	logInfo "Creating tmp file with unique hashes from duplicate files."
	cat ${FILEHASH_DB}|cut -c1-32|sort|uniq -d > ${DUPLICATES_DB}.tmp
	logInfo "Removing current duplicates db."	
	rm ${DUPLICATES_DB} >/dev/null 2>&1 
	touch ${DUPLICATES_DB}
	logInfo "Creating db with duplicate filenames in filehash db..."
	HASHES_TO_SEARCH=`countEntriesInFile ${DUPLICATES_DB}.tmp`
	logInfo "Hashes to search in filehash db: ${HASHES_TO_SEARCH}"
	HASHES_PROCESSED=0
	echo -n "Hashes processed: "
	tput sc 2>/dev/null
	while read line;do
		grep ${line} ${FILEHASH_DB} | cut -c35-|tail -n+2 >> ${DUPLICATES_DB}
		HASHES_PROCESSED=$((${HASHES_PROCESSED} + 1))
		echo -n "${HASHES_PROCESSED}/${HASHES_TO_SEARCH}"
		tput rc 2>/dev/null
	done < ${DUPLICATES_DB}.tmp
	[ -f "${DUPLICATES_DB}.tmp" ] && rm "${DUPLICATES_DB}.tmp"
	echo
	logInfo "Done."
}

function createCopyDuplicatesToArchiveScript() {
	logInfo "Creating script to copy duplicates to archive: ${DUPLICATE_FILES_ARCHIVE_FOLDER}..."
	cat ${DUPLICATES_DB} | sed "s/^/cp -uv --parents '/g" | sed "s/$/' ${DUPLICATE_FILES_ARCHIVE_FOLDER}/g" | sort > ${COPY_DUPLICATES_SCRIPT}
	chmod +x ${COPY_DUPLICATES_SCRIPT}
	logInfo "Script created: ${COPY_DUPLICATES_SCRIPT}"
}

function createDeleteDuplicatesFromRootPathScript() {
	logInfo "Creating script to delete duplicates in root folder: ${ROOT_PATH}..."
	cat ${DUPLICATES_DB} | sed "s/^/rm -v '/g" | sed "s/$/'/g" | sort > ${DELETE_DUPLICATES_FROM_ROOT_SCRIPT}
	chmod +x ${DELETE_DUPLICATES_FROM_ROOT_SCRIPT}
	logInfo "Script created: ${DELETE_DUPLICATES_FROM_ROOT_SCRIPT}"
}

function showDuplicates() {
	logInfo "Show duplicate files:"
	cat "${DUPLICATES_DB}"
	echo "Found `countEntriesInFile ${DUPLICATES_DB} duplicates.`"
}

# Works only with sorted filehashdatabase
function removeDuplicateFileHashDatabaseEntries() {
	logInfo "Removing duplicate file hash entries in database..."
	logInfo "Entries before cleanup: `countEntriesInFile "${FILEHASH_DB}"`"
	cat "${FILEHASH_DB}" | uniq > "${FILEHASH_DB_TMP}"
	mv "${FILEHASH_DB_TMP}" "${FILEHASH_DB}"
	logInfo "Entries after  cleanup: `countEntriesInFile "${FILEHASH_DB}"`"
}

function showUsage() {
	echo "$USAGE_INFO_TEXT"
}

function showHelpText() {
	echo
	echo "Wrong usage. Use -h for help."
	echo
}

function showVersion() {
	echo
	echo "	dupfinder version: ${VERSION}"
	echo
	echo "	Jens Heine <binbash@gmx.net>"
	echo "	and Dennis Brossat"
	echo "	and Benjamin Heine"
	echo
}

function calculateSizeOfFilesInFile() {
        FILENAME="${1}"
	[ -f "${FILENAME}" ] || {
        	echo 0
                return
        }
	SUM_BYTES=0
	while read LINE;do
		FILESIZE=`stat -c "%s" "${LINE}" 2>/dev/null`
		[ "$FILESIZE" ] && SUM_BYTES=$[SUM_BYTES + FILESIZE ]
	done < "${FILENAME}"
#	SUM_BYTES_FORMATTED=`echo "scale=3;$SUM_BYTES/1024/1024/1024"|bc`
	SUM_BYTES_FORMATTED=`awk -v s="$SUM_BYTES" 'BEGIN { printf "%-.3f", s/1024/1024/1024 }'`
	echo "$SUM_BYTES_FORMATTED GB"
}

function showStats() {
	echo
	echo "Dupfinder Statistics"
	echo
	FILE_COUNT_FILEHASH=`countEntriesInFile "${FILEHASH_DB}"`
	FILE_COUNT_FILELIST=`countEntriesInFile "${FILELIST_DB}"`
	FILE_COUNT_DUPLICATES=`countEntriesInFile "${DUPLICATES_DB}"`
#	echo -e "Files in filehash database : ${FILE_COUNT_FILEHASH}\t(`countFileSizeInBytes "${FILEHASH_DB}"`)\tmodified: `stat -c %y "${FILEHASH_DB}"`"
#	echo -e "Files in plain file list   : ${FILE_COUNT_FILELIST}\t(`countFileSizeInBytes "${FILELIST_DB}"`)\tmodified: `stat -c %y "${FILELIST_DB}"`"
#	echo -e "Files in duplicates file   : ${FILE_COUNT_DUPLICATES}\t(`countFileSizeInBytes "${DUPLICATES_DB}"`)\tmodified: `stat -c %y "${DUPLICATES_DB}"`"
	echo -e "Files in filehash database : ${FILE_COUNT_FILEHASH}\t(`countFileSizeInBytes "${FILEHASH_DB}"`)"
	echo -e "Files in plain file list   : ${FILE_COUNT_FILELIST}\t(`countFileSizeInBytes "${FILELIST_DB}"`)"
	echo -n "Size of all files hashed   : "
	tput sc 2>/dev/null
	echo -n "(calculating size of all hashed files...)"
	tput rc 2>/dev/null
	echo -e "`calculateSizeOfFilesInFile "${FILELIST_DB}"`                                              "
	echo -e "Files in duplicates file   : ${FILE_COUNT_DUPLICATES}\t(`countFileSizeInBytes "${DUPLICATES_DB}"`)"
	echo -n "Size of all duplicates     : "
	tput sc 2>/dev/null
	echo -n "(calculating size of duplicates...)"
	tput rc 2>/dev/null
	echo -e "`calculateSizeOfFilesInFile "${DUPLICATES_DB}"`                                              "
	if [ ${FILE_COUNT_FILELIST} -ne 0 ]; then
		DUPLICATES_PERCENT=$((FILE_COUNT_DUPLICATES*100/FILE_COUNT_FILELIST))
	else
		DUPLICATES_PERCENT=0
	fi
	echo -e "Duplicate files            : ${DUPLICATES_PERCENT} %"
	echo
}

function exitIfRootPathIsNotSet() {
	# Check if the rootpath is set
	if [ -z "$ROOT_PATH" ];then
		echo "Error: root path is empty."
		exit 1
	fi
}

function printDuplicatesPercent() {
	HASHES_COUNT=`countEntriesInFile "${FILEHASH_DB}"`
	DUPLICATES_COUNT=`countEntriesInFile "${DUPLICATES_DB}"`
	if [ "${HASHES_COUNT}" -eq 0 ];then
		echo "Found 0 duplicates in 0 files (0%)."
		return
	else
#		DUPLICATES_PERCENT=`echo "100 * $DUPLICATES_COUNT / $HASHES_COUNT" | bc`
		DUPLICATES_PERCENT=`echo $((100 * $DUPLICATES_COUNT / $HASHES_COUNT))`
		echo "Found $DUPLICATES_COUNT duplicates in $HASHES_COUNT files (${DUPLICATES_PERCENT}%)."
	fi
}

function touchDBFiles() {
	[ ! -f ${FILEHASH_DB} ] && {
		logInfo "Filehash DB \"${FILEHASH_DB}\" not found. Touching it."
		touch ${FILEHASH_DB}
	}
	[ ! -f ${FILELIST_DB} ] && {
		logInfo "Filehlist DB \"${FILELIST_DB}\" not found. Touching it."
		touch ${FILELIST_DB}
	}
	[ ! -f ${DUPLICATES_DB} ] && {
		logInfo "Duplicates DB \"${DUPLICATES_DB}\" not found. Touching it."
		touch ${DUPLICATES_DB}
	}
}

function showContentsOfDuplicatesFile() {
	echo
	echo "Show contents of duplicates file:"
	echo
        [ ! -f ${DUPLICATES_DB} ] && {
                logInfo "Duplicates DB \"${DUPLICATES_DB}\" not found."
		return 1
        }
	cat "${DUPLICATES_DB}"
	echo
	echo -e "Files in duplicates file   : `countEntriesInFile "${DUPLICATES_DB}"`\t(`countFileSizeInBytes "${DUPLICATES_DB}"`)\tmodified: `stat -c %y "${DUPLICATES_DB}"`"
	echo -n "Size of all duplicates     : "
	tput sc 2>/dev/null
	echo -n "(calculating size of duplicates...)"
	tput rc 2>/dev/null
	echo -e "`calculateSizeOfFilesInFile "${DUPLICATES_DB}"`                                              "
	echo
}

function showContentsOfHashdatabaseFile() {
	echo "Show contents of hashdatabase file:"
        [ ! -f ${FILEHASH_DB} ] && {
                logInfo "Filehash database \"${FILEHASH_DB}\" not found."
		return 1
        }
	cat "${FILEHASH_DB}"
	echo
        echo -e "Files in filehash database : `countEntriesInFile "${FILEHASH_DB}"`\t(`countFileSizeInBytes "${FILEHASH_DB}"`)\tmodified: `stat -c %y "${FILEHASH_DB}"`"
	echo
}

function checkForCommand() {
        [ ! "${1}" ] && {
                logInfo "Error: no command given to check."
                return 0
        }
        logInfo "Checking if ${1} is installed."
        which "${1}" >/dev/null 2>&1
        RET_VAL=$?
        [ "$RET_VAL" -ne 0 ] && {
                echo "Error: ${1} not found."
                echo "Please install ${1}. For example: apt-get install ${1}"
                return 1
        }
        logInfo "Success: command ${1} is installed."
        return 0
}

#
# check if all needed tools are available
#
function checkDependencies() {
        DEPENDENCY_ERRORS=0
        logInfo "Checking dependencies..."

        checkForCommand "$HASH_CMD"
        let DEPENDENCY_ERRORS=$DEPENDENCY_ERRORS+$?
#        checkForCommand "bc"
#        let DEPENDENCY_ERRORS=$DEPENDENCY_ERRORS+$?
        checkForCommand "awk"
        let DEPENDENCY_ERRORS=$DEPENDENCY_ERRORS+$?
        checkForCommand "wc"
        let DEPENDENCY_ERRORS=$DEPENDENCY_ERRORS+$?
        checkForCommand "diff"
        let DEPENDENCY_ERRORS=$DEPENDENCY_ERRORS+$?
        checkForCommand "stat"
        let DEPENDENCY_ERRORS=$DEPENDENCY_ERRORS+$?

        [ $DEPENDENCY_ERRORS -eq 0 ] && {
                logInfo "Dependency check OK."
                return 0
        }
        logInfo "Dependency check had errors."
        return 1
}


########################################################################################################
# Main
########################################################################################################

# Check if all needed command are installed
checkDependencies || {
        echo "Missing dependecies. Please install the missing commands and restart."
        exit 1
}

# If DB files do not exist touch them
touchDBFiles

ARGUMENTS_EXIST=0
while getopts "acCdfghHnpPr:RsvV" options; do
	ARGUMENTS_EXIST=1
	case "$options" in
		a) ACTION="SEARCH_PATH_FOR_DUPLICATES"
		   ;;
		c) # Calculate hashes for files in plain files filelist
		   ACTION="CALCULATE_HASHES_FOR_FILES_IN_PLAIN_FILELIST_FILE"
		   ;;
		C) # create duplicate files file
		   ACTION="CREATE_DUPLICATES_FILE_FROM_FILEHASH_DATABASE"
		   ;;
		v) # Switch on verbose logging
		   echo "> Verbose mode = ON"
		   DEBUG=1
		   ;;
		d) showContentsOfDuplicatesFile
		   exit 0
		   ;;
		f) ACTION="FIND_FILES_AND_CREATE_PLAIN_FILE_LIST"
		   ;;
		g) ACTION="GENERATE_SCRIPTS"
		   ;;
		h) showUsage
		   exit 0
		   ;;
		H) showContentsOfHashdatabaseFile
		   exit 0
		   ;;
		p) # Create plain files filelist
		   ACTION="CREATE_PLAIN_FILES_FILELIST"
		   ;;
		P) echo "Show contents of plain filelist file:"
		   cat "${FILELIST_DB}"
		   echo "Files in plain file list   : `countEntriesInFile "${FILELIST_DB}"`"
		   exit 0
		   ;;
		r) ROOT_PATH="${OPTARG}"
		   ;;
		R) # Delete filehashdatabase file
		   ACTION="DELETE_FILEHASH_DATABASE_FILES"
		   ;;
		s) showStats
		   exit 0
		   ;;
#		u) DELETE_FILEHASH_DATABASE_ON_NEW_SCAN="0"
#		   logInfo "Use existing filehash database = true"
#		   ;;
		n) RECALC_EXISTING_HASHES=1
		   ;;
		V) ACTION="SHOW_VERSION"
		   showVersion
		   exit 0
		   ;;
		*) showHelpText
		   exit 0
		   ;;
	esac
done

if [ "1" != "$ARGUMENTS_EXIST" ];then
  showHelpText
  exit 1
fi

case "${ACTION}" in
	SEARCH_PATH_FOR_DUPLICATES)
		exitIfRootPathIsNotSet
		createPlainFileList ${ROOT_PATH}
		calculateHashesForPlainfilesFileIntoFileHashDatabase
		createDuplicateFilelist
		printDuplicatesPercent
		showStats
		exit 0
		;;
	CREATE_PLAIN_FILES_FILELIST)
		exitIfRootPathIsNotSet
		createPlainFileList ${ROOT_PATH}
		;;
	CREATE_PLAIN_FILES_FILELIST)
		exitIfRootPathIsNotSet
		createPlainFileList ${ROOT_PATH}
		exit 0
		;;
	CALCULATE_HASHES_FOR_FILES_IN_PLAIN_FILELIST_FILE)
		calculateHashesForPlainfilesFileIntoFileHashDatabase
		exit 0
		;;
	DELETE_FILEHASH_DATABASE_FILES)
		read -p "Delete all databases? (y/Y) : " X
		[ "${X}" = "y" -o "${X}" = "Y" ] && {
			deleteAllDatabases
			echo "Database deleted."
			exit 0
		}
		echo "Aborted."
		exit 0
		;;
	CREATE_DUPLICATES_FILE_FROM_FILEHASH_DATABASE)
		createDuplicateFilelist
		printDuplicatesPercent
		exit 0
		;;
	GENERATE_SCRIPTS)
		echo "Generating scrips..."
		echo "Creating script to copy all duplicates to archive folder..."
		createCopyDuplicatesToArchiveScript
		echo "\"${COPY_DUPLICATES_SCRIPT}\" created."
		echo "Creating script to delete all duplicates..."
		createDeleteDuplicatesFromRootPathScript
		echo "\"${DELETE_DUPLICATES_FROM_ROOT_SCRIPT}\" created."
		echo
		exit 0
		;;
esac

exit 0




